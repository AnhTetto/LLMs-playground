# Mistral-7B’s Finetuning using QLoRA

In this notebook and tutorial, we will fine-tune the Mistral 7B model — which outperforms Llama 2 13B on all tested benchmarks.  

If you get an error like this: OutOfMemoryError: CUDA out of memory, tweak your parameters to make the model less computationally intensive.  
